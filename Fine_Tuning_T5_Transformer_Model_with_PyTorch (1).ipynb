{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine Tuning T5 Transformer Model with PyTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97322844a592408cb262d802605b8cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09e5cafc59444f3db3a6ed594a2ab52f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_32c18057cf584a669f4da290ec4a5cdc",
              "IPY_MODEL_e9fb19ff78c54dfcabeef5da91b291cf"
            ]
          }
        },
        "09e5cafc59444f3db3a6ed594a2ab52f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32c18057cf584a669f4da290ec4a5cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_15f7adf8bf664744a9c9aea4e3282b98",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7e4a3153b4846febdc2793b22a10753"
          }
        },
        "e9fb19ff78c54dfcabeef5da91b291cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_916cbc020cfd403d8bd12cff2ac6cc36",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:00&lt;00:00, 973kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7713a75fb164e4894df8d4464456af4"
          }
        },
        "15f7adf8bf664744a9c9aea4e3282b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7e4a3153b4846febdc2793b22a10753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "916cbc020cfd403d8bd12cff2ac6cc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7713a75fb164e4894df8d4464456af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49c537bc36ac4ca29def2f3ae5ccc3b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16d8582e457c4a8d9a414c9c7ec7ff41",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_abc047b971044d74a99635fa0374340b",
              "IPY_MODEL_47456a16faab41bb87464b6ce71cf21d"
            ]
          }
        },
        "16d8582e457c4a8d9a414c9c7ec7ff41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abc047b971044d74a99635fa0374340b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b41be1aa0f3a4d039f91e59cda007989",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6275412c22464f1cb8ed1d17c4a291bc"
          }
        },
        "47456a16faab41bb87464b6ce71cf21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d0b3516c7f6e4358acf230f5a309f343",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:12&lt;00:00, 94.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fb29326f7124a12b89be4930e926c23"
          }
        },
        "b41be1aa0f3a4d039f91e59cda007989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6275412c22464f1cb8ed1d17c4a291bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0b3516c7f6e4358acf230f5a309f343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fb29326f7124a12b89be4930e926c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57e338674bd44df58961abb1821c1a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_89bcd53032dd40a9a78205053fc6ac00",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a0c15842250b42419e0c1058cd645e65",
              "IPY_MODEL_a8249ab91e074d728cee8593caad226a"
            ]
          }
        },
        "89bcd53032dd40a9a78205053fc6ac00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0c15842250b42419e0c1058cd645e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eafefaaabbc24419843a09051a76acf0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891691430,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891691430,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d42241141ac143ffaf6ce40f2d593d38"
          }
        },
        "a8249ab91e074d728cee8593caad226a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76098970d9784a2985019e5ffc76d539",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:12&lt;00:00, 72.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66c2e1a4744b4b0486e9e22bb8ac927a"
          }
        },
        "eafefaaabbc24419843a09051a76acf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d42241141ac143ffaf6ce40f2d593d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76098970d9784a2985019e5ffc76d539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66c2e1a4744b4b0486e9e22bb8ac927a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh_fApALm1ie"
      },
      "source": [
        "## Import Dataset\r\n",
        "\r\n",
        "We wil be using a News Text Dataset which is having Source Text as a article content and Target text is a one line summary,The both the Source and Target are feeded into a T5 Transformer and then we will be fine tuning its hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "iJJnM_odm1Nu",
        "outputId": "bdfb8d21-28eb-4905-e269-e69bc55d22fa"
      },
      "source": [
        "import pandas as pd\r\n",
        "path = \"/content/drive/MyDrive/outputs/news_summary.csv\"\r\n",
        "df = pd.read_csv(path)\r\n",
        "\r\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines                                               text\n",
              "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd6PQ9RWpQ0D"
      },
      "source": [
        "**PyTorch has a standard way to train any deep learning model. We will first start by writing a Dataset class, followed by training, validation steps and then a main T5Trainer function that will fine-tune our model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvlYJ3J2mtKB",
        "outputId": "a060df9f-3139-4e1c-f04a-7ec90db582a0"
      },
      "source": [
        "!pip install sentencepiece\r\n",
        "!pip install transformers\r\n",
        "!pip install torch\r\n",
        "!pip install rich[jupyter]\r\n",
        "\r\n",
        "# Importing libraries\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "import os\r\n",
        "\r\n",
        "# Importing the T5 modules from huggingface/transformers\r\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\r\n",
        "\r\n",
        "# rich: for a better display on terminal\r\n",
        "from rich.table import Column, Table\r\n",
        "from rich import box\r\n",
        "from rich.console import Console\r\n",
        "\r\n",
        "# define a rich console logger\r\n",
        "console = Console(record=True)\r\n",
        "\r\n",
        "# to display dataframe in ASCII format\r\n",
        "def display_df(df):\r\n",
        "    \"\"\"display dataframe in ASCII format\"\"\"\r\n",
        "\r\n",
        "    console = Console()\r\n",
        "    table = Table(\r\n",
        "        Column(\"source_text\", justify=\"center\"),\r\n",
        "        Column(\"target_text\", justify=\"center\"),\r\n",
        "        title=\"Sample Data\",\r\n",
        "        pad_edge=False,\r\n",
        "        box=box.ASCII,\r\n",
        "    )\r\n",
        "\r\n",
        "    for i, row in enumerate(df.values.tolist()):\r\n",
        "        table.add_row(row[0], row[1])\r\n",
        "\r\n",
        "    console.print(table)\r\n",
        "\r\n",
        "# training logger to log training progress\r\n",
        "training_logger = Table(\r\n",
        "    Column(\"Epoch\", justify=\"center\"),\r\n",
        "    Column(\"Steps\", justify=\"center\"),\r\n",
        "    Column(\"Loss\", justify=\"center\"),\r\n",
        "    title=\"Training Status\",\r\n",
        "    pad_edge=False,\r\n",
        "    box=box.ASCII,\r\n",
        ")\r\n",
        "\r\n",
        "# Setting up the device for GPU usage\r\n",
        "from torch import cuda\r\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.95)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.3.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: rich[jupyter] in /usr/local/lib/python3.6/dist-packages (9.10.0)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from rich[jupyter]) (0.4.4)\n",
            "Requirement already satisfied: typing-extensions<4.0.0,>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from rich[jupyter]) (3.7.4.3)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from rich[jupyter]) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from rich[jupyter]) (2.6.1)\n",
            "Requirement already satisfied: dataclasses<0.9,>=0.7; python_version >= \"3.6\" and python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from rich[jupyter]) (0.8)\n",
            "Requirement already satisfied: ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\" in /usr/local/lib/python3.6/dist-packages (from rich[jupyter]) (7.6.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (4.10.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (4.3.3)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (5.1.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (1.0.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (5.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (1.15.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (4.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (53.0.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (1.0.18)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (5.3.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (22.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (2.8.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (0.2.5)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (1.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (0.9.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (1.1.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (3.3.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (1.4.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1; extra == \"jupyter\"->rich[jupyter]) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsxDiKqno9c3"
      },
      "source": [
        "class YourDataSetClass(Dataset):\r\n",
        "    \"\"\"\r\n",
        "    Creating a custom dataset for reading the dataset and\r\n",
        "    loading it into the dataloader to pass it to the\r\n",
        "    neural network for finetuning the model\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(\r\n",
        "        self, dataframe, tokenizer, source_len, target_len, source_text, target_text\r\n",
        "    ):\r\n",
        "        \"\"\"\r\n",
        "        Initializes a Dataset class\r\n",
        "\r\n",
        "        Args:\r\n",
        "            dataframe (pandas.DataFrame): Input dataframe\r\n",
        "            tokenizer (transformers.tokenizer): Transformers tokenizer\r\n",
        "            source_len (int): Max length of source text\r\n",
        "            target_len (int): Max length of target text\r\n",
        "            source_text (str): column name of source text\r\n",
        "            target_text (str): column name of target text\r\n",
        "        \"\"\"\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        self.data = dataframe\r\n",
        "        self.source_len = source_len\r\n",
        "        self.summ_len = target_len\r\n",
        "        self.target_text = self.data[target_text]\r\n",
        "        self.source_text = self.data[source_text]\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        \"\"\"returns the length of dataframe\"\"\"\r\n",
        "\r\n",
        "        return len(self.target_text)\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        \"\"\"return the input ids, attention masks and target ids\"\"\"\r\n",
        "\r\n",
        "        source_text = str(self.source_text[index])\r\n",
        "        target_text = str(self.target_text[index])\r\n",
        "\r\n",
        "        # cleaning data so as to ensure data is in string type\r\n",
        "        source_text = \" \".join(source_text.split())\r\n",
        "        target_text = \" \".join(target_text.split())\r\n",
        "\r\n",
        "        source = self.tokenizer.batch_encode_plus(\r\n",
        "            [source_text],\r\n",
        "            max_length=self.source_len,\r\n",
        "            pad_to_max_length=True,\r\n",
        "            truncation=True,\r\n",
        "            padding=\"max_length\",\r\n",
        "            return_tensors=\"pt\",\r\n",
        "        )\r\n",
        "        target = self.tokenizer.batch_encode_plus(\r\n",
        "            [target_text],\r\n",
        "            max_length=self.summ_len,\r\n",
        "            pad_to_max_length=True,\r\n",
        "            truncation=True,\r\n",
        "            padding=\"max_length\",\r\n",
        "            return_tensors=\"pt\",\r\n",
        "        )\r\n",
        "\r\n",
        "        source_ids = source[\"input_ids\"].squeeze()\r\n",
        "        source_mask = source[\"attention_mask\"].squeeze()\r\n",
        "        target_ids = target[\"input_ids\"].squeeze()\r\n",
        "        target_mask = target[\"attention_mask\"].squeeze()\r\n",
        "\r\n",
        "        return {\r\n",
        "            \"source_ids\": source_ids.to(dtype=torch.long),\r\n",
        "            \"source_mask\": source_mask.to(dtype=torch.long),\r\n",
        "            \"target_ids\": target_ids.to(dtype=torch.long),\r\n",
        "            \"target_ids_y\": target_ids.to(dtype=torch.long),\r\n",
        "        }\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0cb-kHTqTZT"
      },
      "source": [
        "def train(epoch, tokenizer, model, device, loader, optimizer):\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Function to be called for training with the parameters passed from main function\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    model.train()\r\n",
        "    for _, data in enumerate(loader, 0):\r\n",
        "        y = data[\"target_ids\"].to(device, dtype=torch.long)\r\n",
        "        y_ids = y[:, :-1].contiguous()\r\n",
        "        lm_labels = y[:, 1:].clone().detach()\r\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\r\n",
        "        ids = data[\"source_ids\"].to(device, dtype=torch.long)\r\n",
        "        mask = data[\"source_mask\"].to(device, dtype=torch.long)\r\n",
        "\r\n",
        "        outputs = model(\r\n",
        "            input_ids=ids,\r\n",
        "            attention_mask=mask,\r\n",
        "            decoder_input_ids=y_ids,\r\n",
        "            labels=lm_labels,\r\n",
        "        )\r\n",
        "        loss = outputs[0]\r\n",
        "\r\n",
        "        if _ % 10 == 0:\r\n",
        "            training_logger.add_row(str(epoch), str(_), str(loss))\r\n",
        "            console.print(training_logger)\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r05diR23qlU3"
      },
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  Function to evaluate model for predictions\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  model.eval()\r\n",
        "  predictions = []\r\n",
        "  actuals = []\r\n",
        "  with torch.no_grad():\r\n",
        "      for _, data in enumerate(loader, 0):\r\n",
        "          y = data['target_ids'].to(device, dtype = torch.long)\r\n",
        "          ids = data['source_ids'].to(device, dtype = torch.long)\r\n",
        "          mask = data['source_mask'].to(device, dtype = torch.long)\r\n",
        "\r\n",
        "          generated_ids = model.generate(\r\n",
        "              input_ids = ids,\r\n",
        "              attention_mask = mask, \r\n",
        "              max_length=150, \r\n",
        "              num_beams=2,\r\n",
        "              repetition_penalty=2.5, \r\n",
        "              length_penalty=1.0, \r\n",
        "              early_stopping=True\r\n",
        "              )\r\n",
        "          preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\r\n",
        "          target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\r\n",
        "          if _%10==0:\r\n",
        "              console.print(f'Completed {_}')\r\n",
        "\r\n",
        "          predictions.extend(preds)\r\n",
        "          actuals.extend(target)\r\n",
        "  return predictions, actuals\r\n",
        "\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgFTvodbqpir"
      },
      "source": [
        "def T5Trainer(\r\n",
        "    dataframe, source_text, target_text, model_params, output_dir=\"./outputs/\"\r\n",
        "):\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    T5 trainer\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Set random seeds and deterministic pytorch for reproducibility\r\n",
        "    torch.manual_seed(model_params[\"SEED\"])  # pytorch random seed\r\n",
        "    np.random.seed(model_params[\"SEED\"])  # numpy random seed\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "\r\n",
        "    # logging\r\n",
        "    console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\r\n",
        "\r\n",
        "    # tokenzier for encoding the text\r\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\r\n",
        "\r\n",
        "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary.\r\n",
        "    # Further this model is sent to device (GPU/TPU) for using the hardware.\r\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\r\n",
        "    model = model.to(device)\r\n",
        "\r\n",
        "    # logging\r\n",
        "    console.log(f\"[Data]: Reading data...\\n\")\r\n",
        "\r\n",
        "    # Importing the raw dataset\r\n",
        "    dataframe = dataframe[[source_text, target_text]]\r\n",
        "    display_df(dataframe.head(2))\r\n",
        "\r\n",
        "    # Creation of Dataset and Dataloader\r\n",
        "    # Defining the train size. So 80% of the data will be used for training and the rest for validation.\r\n",
        "    train_size = 0.8\r\n",
        "    train_dataset = dataframe.sample(frac=train_size, random_state=model_params[\"SEED\"])\r\n",
        "    val_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\r\n",
        "    train_dataset = train_dataset.reset_index(drop=True)\r\n",
        "\r\n",
        "    console.print(f\"FULL Dataset: {dataframe.shape}\")\r\n",
        "    console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\r\n",
        "    console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\r\n",
        "\r\n",
        "    # Creating the Training and Validation dataset for further creation of Dataloader\r\n",
        "    training_set = YourDataSetClass(\r\n",
        "        train_dataset,\r\n",
        "        tokenizer,\r\n",
        "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\r\n",
        "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\r\n",
        "        source_text,\r\n",
        "        target_text,\r\n",
        "    )\r\n",
        "    val_set = YourDataSetClass(\r\n",
        "        val_dataset,\r\n",
        "        tokenizer,\r\n",
        "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\r\n",
        "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\r\n",
        "        source_text,\r\n",
        "        target_text,\r\n",
        "    )\r\n",
        "\r\n",
        "    # Defining the parameters for creation of dataloaders\r\n",
        "    train_params = {\r\n",
        "        \"batch_size\": model_params[\"TRAIN_BATCH_SIZE\"],\r\n",
        "        \"shuffle\": True,\r\n",
        "        \"num_workers\": 0,\r\n",
        "    }\r\n",
        "\r\n",
        "    val_params = {\r\n",
        "        \"batch_size\": model_params[\"VALID_BATCH_SIZE\"],\r\n",
        "        \"shuffle\": False,\r\n",
        "        \"num_workers\": 0,\r\n",
        "    }\r\n",
        "\r\n",
        "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\r\n",
        "    training_loader = DataLoader(training_set, **train_params)\r\n",
        "    val_loader = DataLoader(val_set, **val_params)\r\n",
        "\r\n",
        "    # Defining the optimizer that will be used to tune the weights of the network in the training session.\r\n",
        "    optimizer = torch.optim.Adam(\r\n",
        "        params=model.parameters(), lr=model_params[\"LEARNING_RATE\"]\r\n",
        "    )\r\n",
        "\r\n",
        "    # Training loop\r\n",
        "    console.log(f\"[Initiating Fine Tuning]...\\n\")\r\n",
        "\r\n",
        "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\r\n",
        "        train(epoch, tokenizer, model, device, training_loader, optimizer)\r\n",
        "\r\n",
        "    console.log(f\"[Saving Model]...\\n\")\r\n",
        "    # Saving the model after training\r\n",
        "    path = os.path.join(output_dir, \"model_files\")\r\n",
        "    model.save_pretrained(path)\r\n",
        "    tokenizer.save_pretrained(path)\r\n",
        "\r\n",
        "    # evaluating test dataset\r\n",
        "    console.log(f\"[Initiating Validation]...\\n\")\r\n",
        "    for epoch in range(model_params[\"VAL_EPOCHS\"]):\r\n",
        "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\r\n",
        "        final_df = pd.DataFrame({\"Generated Text\": predictions, \"Actual Text\": actuals})\r\n",
        "        final_df.to_csv(os.path.join(output_dir, \"predictions.csv\"))\r\n",
        "\r\n",
        "    console.save_text(os.path.join(output_dir, \"logs.txt\"))\r\n",
        "\r\n",
        "    console.log(f\"[Validation Completed.]\\n\")\r\n",
        "    console.print(\r\n",
        "        f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\"\r\n",
        "    )\r\n",
        "    console.print(\r\n",
        "        f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\"\r\n",
        "    )\r\n",
        "    console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")\r\n",
        " "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0NOZFxTr7U2"
      },
      "source": [
        "\r\n",
        "# let's define model parameters specific to T5\r\n",
        "model_params = {\r\n",
        "    \"MODEL\": \"t5-base\",  # model_type: t5-base/t5-large\r\n",
        "    \"TRAIN_BATCH_SIZE\": 8,  # training batch size\r\n",
        "    \"VALID_BATCH_SIZE\": 8,  # validation batch size\r\n",
        "    \"TRAIN_EPOCHS\": 3,  # number of training epochs\r\n",
        "    \"VAL_EPOCHS\": 1,  # number of validation epochs\r\n",
        "    \"LEARNING_RATE\": 1e-4,  # learning rate\r\n",
        "    \"MAX_SOURCE_TEXT_LENGTH\": 512,  # max length of source text\r\n",
        "    \"MAX_TARGET_TEXT_LENGTH\": 50,  # max length of target text\r\n",
        "    \"SEED\": 42,  # set seed for reproducibility\r\n",
        "}\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI0tBGJTxigk"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "97322844a592408cb262d802605b8cba",
            "09e5cafc59444f3db3a6ed594a2ab52f",
            "32c18057cf584a669f4da290ec4a5cdc",
            "e9fb19ff78c54dfcabeef5da91b291cf",
            "15f7adf8bf664744a9c9aea4e3282b98",
            "f7e4a3153b4846febdc2793b22a10753",
            "916cbc020cfd403d8bd12cff2ac6cc36",
            "f7713a75fb164e4894df8d4464456af4",
            "49c537bc36ac4ca29def2f3ae5ccc3b8",
            "16d8582e457c4a8d9a414c9c7ec7ff41",
            "abc047b971044d74a99635fa0374340b",
            "47456a16faab41bb87464b6ce71cf21d",
            "b41be1aa0f3a4d039f91e59cda007989",
            "6275412c22464f1cb8ed1d17c4a291bc",
            "d0b3516c7f6e4358acf230f5a309f343",
            "8fb29326f7124a12b89be4930e926c23",
            "57e338674bd44df58961abb1821c1a0a",
            "89bcd53032dd40a9a78205053fc6ac00",
            "a0c15842250b42419e0c1058cd645e65",
            "a8249ab91e074d728cee8593caad226a",
            "eafefaaabbc24419843a09051a76acf0",
            "d42241141ac143ffaf6ce40f2d593d38",
            "76098970d9784a2985019e5ffc76d539",
            "66c2e1a4744b4b0486e9e22bb8ac927a"
          ]
        },
        "id": "oTUaXB8Jr7I_",
        "outputId": "f919f5f5-9c1e-48cd-c079-f373629a447b"
      },
      "source": [
        "# T5 accepts prefix of the task to be performed:\r\n",
        "# Since we are summarizing, let's add summarize to source text as a prefix\r\n",
        "df[\"text\"] = \"summarize: \" + df[\"text\"]\r\n",
        "\r\n",
        "T5Trainer(dataframe=df[:500], source_text=\"text\", target_text=\"headlines\", model_params=model_params, output_dir=\"/content/drive/MyDrive/outputs\")\r\n",
        "\r\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10:47:51] [Model]: Loading t5-base...        <ipython-input-12-b744ab2430ed>:16\n",
            "                                                                                \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97322844a592408cb262d802605b8cba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49c537bc36ac4ca29def2f3ae5ccc3b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57e338674bd44df58961abb1821c1a0a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[10:48:23] [Data]: Reading data...            <ipython-input-12-b744ab2430ed>:27\n",
            "                                                                                \n",
            "                                  Sample Data                                   \n",
            "+------------------------------------------------------------------------------+\n",
            "|             source_text              |              target_text              |\n",
            "|--------------------------------------+---------------------------------------|\n",
            "|summarize: Saurav Kant, an alumnus of |  upGrad learner switches to career in |\n",
            "|  upGrad and IIIT-B's PG Program in   |      ML & Al with 90% salary hike     |\n",
            "|   Machine learning and Artificial    |                                       |\n",
            "|   Intelligence, was a Sr Systems     |                                       |\n",
            "|  Engineer at Infosys with almost 5   |                                       |\n",
            "|years of work experience. The program |                                       |\n",
            "|   and upGrad's 360-degree career     |                                       |\n",
            "| support helped him transition to a   |                                       |\n",
            "|Data Scientist at Tech Mahindra with  |                                       |\n",
            "|  90% salary hike. upGrad's Online    |                                       |\n",
            "| Power Learning has powered 3 lakh+   |                                       |\n",
            "|              careers.                |                                       |\n",
            "| summarize: Kunal Shah's credit card  |    Delhi techie wins free food from   |\n",
            "|  bill payment platform, CRED, gave   |      Swiggy for one year on CRED      |\n",
            "|users a chance to win free food from  |                                       |\n",
            "|Swiggy for one year. Pranav Kaushik,  |                                       |\n",
            "| a Delhi techie, bagged this reward   |                                       |\n",
            "|after spending 2000 CRED coins. Users |                                       |\n",
            "| get one CRED coin per rupee of bill  |                                       |\n",
            "|  paid, which can be used to avail    |                                       |\n",
            "|   rewards from brands like Ixigo,    |                                       |\n",
            "| BookMyShow, UberEats, Cult.Fit and   |                                       |\n",
            "|                more.                 |                                       |\n",
            "+------------------------------------------------------------------------------+\n",
            "FULL Dataset: (500, 2)\n",
            "TRAIN Dataset: (400, 2)\n",
            "TEST Dataset: (100, 2)\n",
            "\n",
            "           [Initiating Fine Tuning]...        <ipython-input-12-b744ab2430ed>:85\n",
            "                                                                                \n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  40   | tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  40   | tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |   0   | tensor(2.2411, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  40   | tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |   0   | tensor(2.2411, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  10   | tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  40   | tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |   0   | tensor(2.2411, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  10   | tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  20   | tensor(1.9091, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  40   | tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |   0   | tensor(2.2411, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  10   | tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  20   | tensor(1.9091, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  30   | tensor(2.0122, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  40   | tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |   0   | tensor(2.2411, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  10   | tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  20   | tensor(1.9091, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  30   | tensor(2.0122, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  40   | tensor(1.5261, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  40   | tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |   0   | tensor(2.2411, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  10   | tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  20   | tensor(1.9091, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  30   | tensor(2.0122, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  40   | tensor(1.5261, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |   0   | tensor(1.6496, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  40   | tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |   0   | tensor(2.2411, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  10   | tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  20   | tensor(1.9091, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  30   | tensor(2.0122, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  40   | tensor(1.5261, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |   0   | tensor(1.6496, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |  10   | tensor(1.1971, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  40   | tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |   0   | tensor(2.2411, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  10   | tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  20   | tensor(1.9091, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  30   | tensor(2.0122, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  40   | tensor(1.5261, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |   0   | tensor(1.6496, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |  10   | tensor(1.1971, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |  20   | tensor(1.6908, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  40   | tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |   0   | tensor(2.2411, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  10   | tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  20   | tensor(1.9091, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  30   | tensor(2.0122, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  40   | tensor(1.5261, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |   0   | tensor(1.6496, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |  10   | tensor(1.1971, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |  20   | tensor(1.6908, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |  30   | tensor(1.4069, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "                              Training Status                               \n",
            "+--------------------------------------------------------------------------+\n",
            "|Epoch | Steps |                            Loss                           |\n",
            "|------+-------+-----------------------------------------------------------|\n",
            "|  0   |   0   | tensor(8.5338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  10   | tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  20   | tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  30   | tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  0   |  40   | tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |   0   | tensor(2.2411, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  10   | tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  20   | tensor(1.9091, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  30   | tensor(2.0122, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  1   |  40   | tensor(1.5261, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |   0   | tensor(1.6496, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |  10   | tensor(1.1971, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |  20   | tensor(1.6908, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |  30   | tensor(1.4069, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "|  2   |  40   | tensor(2.1261, device='cuda:0', grad_fn=<NllLossBackward>)|\n",
            "+--------------------------------------------------------------------------+\n",
            "[10:51:04] [Saving Model]...                  <ipython-input-12-b744ab2430ed>:90\n",
            "                                                                                \n",
            "[10:51:08] [Initiating Validation]...         <ipython-input-12-b744ab2430ed>:97\n",
            "                                                                                \n",
            "Completed 0\n",
            "Completed 10\n",
            "[10:51:52] [Validation Completed.]           <ipython-input-12-b744ab2430ed>:105\n",
            "                                                                                \n",
            "[Model] Model saved @ /content/drive/MyDrive/outputs/model_files\n",
            "\n",
            "[Validation] Generation on Validation data saved @ \n",
            "/content/drive/MyDrive/outputs/predictions.csv\n",
            "\n",
            "[Logs] Logs saved @ /content/drive/MyDrive/outputs/logs.txt\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh9mrTJ67U9U"
      },
      "source": [
        "pred = pd.read_csv('/content/drive/MyDrive/outputs/predictions.csv')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "lbRldE9iFy1Y",
        "outputId": "32b52a85-9ff3-43f0-cb07-49a0e95ff9b9"
      },
      "source": [
        "pred.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Generated Text</th>\n",
              "      <th>Actual Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>former stripper gave doctor lap dance to persu...</td>\n",
              "      <td>Pharma exec gave doctor a lap dance to sell me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PM Modi says opposition talks only about Modi ...</td>\n",
              "      <td>I think the opposition even dreams about me: P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ISRO unveils human space flight centre for its...</td>\n",
              "      <td>ISRO unveils Bengaluru centre for manned space...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Goa CM accuses Rahul of using his visit to an ...</td>\n",
              "      <td>CM Parrikar under pressure from PM after our G...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                        Actual Text\n",
              "0           0  ...  Delhi techie wins free food from Swiggy for on...\n",
              "1           1  ...  Pharma exec gave doctor a lap dance to sell me...\n",
              "2           2  ...  I think the opposition even dreams about me: P...\n",
              "3           3  ...  ISRO unveils Bengaluru centre for manned space...\n",
              "4           4  ...  CM Parrikar under pressure from PM after our G...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9hDJ455F0x_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}